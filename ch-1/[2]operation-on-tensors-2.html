<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Tensor的基本操作：合并、分割以及统计 | 工具箱的深度学习记事簿</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/statics/logo.svg">
    <meta name="description" content="这里包含了我从入门到依然在入门的过程中接触到的大部分知识。翻翻目录，也许能找到有用的">
    <meta name="keywords" content="Akasaki,Deep learning,Machine learning,工具箱,工具箱的深度学习记事簿,Akasaki的深度学习记事簿">
    
    <link rel="preload" href="/assets/css/0.styles.90685b8c.css" as="style"><link rel="preload" href="/assets/js/app.a1fbffca.js" as="script"><link rel="preload" href="/assets/js/2.8096074b.js" as="script"><link rel="preload" href="/assets/js/40.716fd348.js" as="script"><link rel="prefetch" href="/assets/js/10.a686cd20.js"><link rel="prefetch" href="/assets/js/11.19e9baf6.js"><link rel="prefetch" href="/assets/js/12.9212f282.js"><link rel="prefetch" href="/assets/js/13.7d0f7067.js"><link rel="prefetch" href="/assets/js/14.4a36e2d7.js"><link rel="prefetch" href="/assets/js/15.e1769a04.js"><link rel="prefetch" href="/assets/js/16.fd1042ef.js"><link rel="prefetch" href="/assets/js/17.f934604d.js"><link rel="prefetch" href="/assets/js/18.bc63a823.js"><link rel="prefetch" href="/assets/js/19.5adad4c4.js"><link rel="prefetch" href="/assets/js/20.0e6892e6.js"><link rel="prefetch" href="/assets/js/21.884c24bc.js"><link rel="prefetch" href="/assets/js/22.3d7bcd74.js"><link rel="prefetch" href="/assets/js/23.b63f63e0.js"><link rel="prefetch" href="/assets/js/24.aec13a9a.js"><link rel="prefetch" href="/assets/js/25.c5426924.js"><link rel="prefetch" href="/assets/js/26.3eb3ba10.js"><link rel="prefetch" href="/assets/js/27.024a3e04.js"><link rel="prefetch" href="/assets/js/28.2772c9bc.js"><link rel="prefetch" href="/assets/js/29.f8ff87be.js"><link rel="prefetch" href="/assets/js/3.98a4c7dc.js"><link rel="prefetch" href="/assets/js/30.50fb28dc.js"><link rel="prefetch" href="/assets/js/31.e24576ff.js"><link rel="prefetch" href="/assets/js/32.9b004a72.js"><link rel="prefetch" href="/assets/js/33.516e30b3.js"><link rel="prefetch" href="/assets/js/34.fce7f963.js"><link rel="prefetch" href="/assets/js/35.dbf61b38.js"><link rel="prefetch" href="/assets/js/36.f3d6b628.js"><link rel="prefetch" href="/assets/js/37.90bb0caf.js"><link rel="prefetch" href="/assets/js/38.6eac4913.js"><link rel="prefetch" href="/assets/js/39.7f5e2f13.js"><link rel="prefetch" href="/assets/js/4.0620af2a.js"><link rel="prefetch" href="/assets/js/41.bb24042a.js"><link rel="prefetch" href="/assets/js/42.c9635060.js"><link rel="prefetch" href="/assets/js/43.b27f3f72.js"><link rel="prefetch" href="/assets/js/44.621812ce.js"><link rel="prefetch" href="/assets/js/45.17e3feb2.js"><link rel="prefetch" href="/assets/js/46.e72b5883.js"><link rel="prefetch" href="/assets/js/47.92f030b3.js"><link rel="prefetch" href="/assets/js/48.eb61d01c.js"><link rel="prefetch" href="/assets/js/49.40e72ee7.js"><link rel="prefetch" href="/assets/js/5.48054ee2.js"><link rel="prefetch" href="/assets/js/50.285dbe55.js"><link rel="prefetch" href="/assets/js/51.bd3fd655.js"><link rel="prefetch" href="/assets/js/52.6e2aafec.js"><link rel="prefetch" href="/assets/js/53.6fdc61bc.js"><link rel="prefetch" href="/assets/js/54.199b7b93.js"><link rel="prefetch" href="/assets/js/55.0eaa332d.js"><link rel="prefetch" href="/assets/js/56.d922b396.js"><link rel="prefetch" href="/assets/js/57.b8b028de.js"><link rel="prefetch" href="/assets/js/6.172b3315.js"><link rel="prefetch" href="/assets/js/7.c978e4d5.js"><link rel="prefetch" href="/assets/js/8.13e9f00e.js"><link rel="prefetch" href="/assets/js/9.b094690e.js">
    <link rel="stylesheet" href="/assets/css/0.styles.90685b8c.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">工具箱的深度学习记事簿</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://github.com/VisualDust/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://github.com/VisualDust/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第零章：在开始之前</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第一章上：HelloWorld</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第一章下：深度学习基础</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第二章上：卷积神经网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第二章下：经典卷积神经网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第三章上：谈一些计算机视觉方向</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第三章下：一些计算机视觉任务</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>附录：永远是你的好朋友</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>第-1章：TensorFlow编程策略</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ch-1/[1]operation-on-tensors-1.html" class="sidebar-link">Tensor的基本操作：索引、切片和广播</a></li><li><a href="/ch-1/[2]operation-on-tensors-2.html" class="active sidebar-link">Tensor的基本操作：合并、分割以及统计</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/ch-1/[2]operation-on-tensors-2.html#合并与分割-merge-and-split" class="sidebar-link">合并与分割(Merge and split)</a></li><li class="sidebar-sub-header"><a href="/ch-1/[2]operation-on-tensors-2.html#数据统计" class="sidebar-link">数据统计</a></li></ul></li><li><a href="/ch-1/[3]operator-for-tensors.html" class="sidebar-link">张量的基本数学运算</a></li><li><a href="/ch-1/[4]tensorflow-strategy.html" class="sidebar-link">TensorFlow编程策略</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>第-2章：数字信号处理（DSP）</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>魔法部日志（又名论文阅读日志）</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="tensor的基本操作-合并、分割以及统计"><a href="#tensor的基本操作-合并、分割以及统计" class="header-anchor">#</a> Tensor的基本操作：合并、分割以及统计</h1> <h2 id="合并与分割-merge-and-split"><a href="#合并与分割-merge-and-split" class="header-anchor">#</a> 合并与分割(Merge and split)</h2> <ul><li>tf.concat</li> <li>tf.split</li> <li>tf.stack</li> <li>tf.unstack</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># importing</span>
<span class="token keyword">import</span> os
<span class="token comment"># changing env log level</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'TF_CPP_MIN_LOG_LEVEL'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'2'</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> optimizers
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="concat"><a href="#concat" class="header-anchor">#</a> concat</h3> <p>concat用于张量的拼接操作。例如：一共有六个班级需要统计成绩。其中第一个人统计前四个班级的成绩，另一个人统计后两个班级的成绩。假设每个班有35人，每个人有八门科目的成绩，那么两个人获得的成绩单的shape应该分别是[4,35,8]和[2,35,8]，拼接后的成绩单的shape应该是[6,35,8]。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># The operation of concat is seemingly two steps. 1. broadcast. 2. combine </span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>(6, 35, 8)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>另外一个类似的场景是两个人统计一个班级的成绩信息，该班级一共有35名学生，第一个人统计前32名学生的成绩，第二个人统计后3名学生的成绩，拼接后得到全班的总成绩单。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># The operation of concat is seemingly two steps. 1. broadcast. 2. combine </span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>(1, 35, 8)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>当然也有这样的场景：现在有四个班级的人考了总共16门考试，其成绩分别记录在了两张表中，每张表记录了8门成绩。现在要将这些成绩放入同一张表：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>(4, 35, 16)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>请注意这两个场景在运算时的区别是基于哪个维度进行拼接。第一种场景下对第0维度进行拼接，第二种场景下对第一维度进行拼接。</p> <ul><li>concat的使用限制条件为：出了要拼接的维度的大小可以不等之外其它维度需要相等。</li></ul> <h3 id="stack"><a href="#stack" class="header-anchor">#</a> stack</h3> <p>stack用于张量的堆叠操作。例如：现在有两个班级的成绩信息，张量结构为[class,student,scoer]。这两个班级分别属于两个学校，现在要将它们放入一张成绩表中，但是要能区分他们的学校。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># add a new dim and combine them</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>(2, 4, 35, 8)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>stack可选要扩展维度的位置，例如，我们希望将学校一列放在最后：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># add a new dim and combine them</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>(4, 35, 8, 2)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>不过一般习惯上把更大的维度（学校）放在前面。</p> <ul><li>stack的使用限制条件为shape相等。</li></ul> <h3 id="unstack"><a href="#unstack" class="header-anchor">#</a> unstack</h3> <p>对应stack，也有unstack。unstack可以在指定的axis上将tensor打散为该axis的size份</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># add a new dim and combine them</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;shape of the origin : &quot;</span><span class="token punctuation">,</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment"># unstack</span>
a_2<span class="token punctuation">,</span>b_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>c<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after unstack : a2:&quot;</span><span class="token punctuation">,</span>a_2<span class="token punctuation">.</span>shape<span class="token punctuation">,</span><span class="token string">&quot;,b2:&quot;</span><span class="token punctuation">,</span>b_2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>shape of the origin :  (2, 4, 35, 8)
after unstack : a2: (4, 35, 8) ,b2: (4, 35, 8)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="split"><a href="#split" class="header-anchor">#</a> split</h3> <p>unstack的使用场景有限。split的功能更加强大。split大体上有两种用法：</p> <ul><li>第一种：num_or_size_splits是数字，例如&quot;num_or_size_splits=2&quot;的情况，split会将tensor再指定的axis上分成两半。</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># add a new dim and combine them</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;shape of the origin : &quot;</span><span class="token punctuation">,</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment"># split into two part on axis 0</span>
res <span class="token operator">=</span> tf<span class="token punctuation">.</span>split<span class="token punctuation">(</span>c<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>num_or_size_splits<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after split into two part, len = &quot;</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;, shape = &quot;</span><span class="token punctuation">,</span>res<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span><span class="token string">&quot; and &quot;</span><span class="token punctuation">,</span>res<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>shape of the origin :  (2, 4, 35, 8)
after split into two part, len =  2 , shape =  (1, 4, 35, 8)  and  (1, 4, 35, 8)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li>第二种：num_or_size_splits是一个list，例如&quot;num_or_size_splits=[1,2,3]&quot;的情况，split会将tensor在指定的axis上分为这个list的size份，在这里是3份，每份的相对大小分别是1、2、3。</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">35</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># add a new dim and combine them</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;shape of the origin : &quot;</span><span class="token punctuation">,</span>c<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment"># split into three part on axis 3, relative size = 2 ,2 ,4</span>
res <span class="token operator">=</span> tf<span class="token punctuation">.</span>split<span class="token punctuation">(</span>c<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>num_or_size_splits<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>shape of the origin :  (2, 4, 35, 8)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="数据统计"><a href="#数据统计" class="header-anchor">#</a> 数据统计</h2> <ul><li>tf.norm：张量范数（一范数、二范数、...、无穷范数）</li> <li>tf.reduce_min：最小值</li> <li>tf,reduce_max：最大值</li> <li>tf.argmin：最小值位置</li> <li>tf.argmax：最大值位置</li> <li>tf.equal：张量比较</li> <li>tf.unique：独特值</li></ul> <h3 id="tf-norm"><a href="#tf-norm" class="header-anchor">#</a> tf.norm</h3> <p>为了好理解，暂时只讨论向量的范数。向量的二范数的公式为：</p> <p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup><msqrt><mrow><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></msubsup><msubsup><mi>x</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">^2\sqrt{sum_{i=1}^{size}x_i^2}
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.5413250000000001em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.298675em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8064640000000001em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27686399999999994em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959080000000001em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27686399999999994em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.2586749999999998em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5413250000000001em;"><span></span></span></span></span></span></span></span></span></span></p> <p>向量的n范数的公式为：</p> <p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mrow></mrow><mi>n</mi></msup><msqrt><mrow><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></msubsup><msubsup><mi>x</mi><mi>i</mi><mi>n</mi></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">^n\sqrt{sum_{i=1}^{size}x_i^n}
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.5413250000000001em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.298675em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8064640000000001em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27686399999999994em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6461920000000001em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27686399999999994em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.2586749999999998em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5413250000000001em;"><span></span></span></span></span></span></span></span></span></span></p> <p>可以理解为：范数是一个函数，是一个向量到数值的映射。向量之间无法比较大小，进行范数运算之后就能直接比较大小了。再换句话理解，这是一种特殊的&quot;欧氏距离(x)&quot;，可以比较向量到远点的距离(x)（我瞎理解的）。</p> <p>先来一个小一点的tensor：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 二范数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">,</span><span class="token string">&quot;\nafter norm: &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 验证一下二范数的运算方式和我们上面说的是否一致</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">,</span><span class="token string">&quot;\nafter square-square-aqrt : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;They are the same&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  tf.Tensor(
[[1. 1.]
 [1. 1.]], shape=(2, 2), dtype=float32) 
after norm:  tf.Tensor(2.0, shape=(), dtype=float32)
origin =  tf.Tensor(
[[1. 1.]
 [1. 1.]], shape=(2, 2), dtype=float32) 
after square-square-aqrt :  tf.Tensor(2.0, shape=(), dtype=float32)
They are the same
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>大一点的tensor：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># more complex example</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">.</span>shape<span class="token punctuation">,</span><span class="token string">&quot;\nafter norm: &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token comment"># 验证一下二范数的运算方式和我们上面说的是否一致</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">.</span>shape<span class="token punctuation">,</span><span class="token string">&quot;\nafter square-square-aqrt : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;They are the same&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  (4, 28, 28, 3) 
after norm:  tf.Tensor(96.99484, shape=(), dtype=float32)
origin =  (4, 28, 28, 3) 
after square-square-aqrt :  tf.Tensor(96.99484, shape=(), dtype=float32)
They are the same
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>norm除了可以作用在整个张量上，也可以作用在某一个维度上。大概可以理解为对这个维度进行一次unstack然后再对unstack出来的每一个向量求norm。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># norm working on specific axis</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">.</span>shape<span class="token punctuation">,</span><span class="token string">&quot;\nafter norm on axis = 3 : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  (4, 28, 28, 3) 
after norm on axis = 3 :  tf.Tensor(
[[[1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  ...
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]]

 [[1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  ...
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]]

 [[1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  ...
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]]

 [[1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  ...
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]
  [1.7320508 1.7320508 1.7320508 ... 1.7320508 1.7320508 1.7320508]]], shape=(4, 28, 28), dtype=float32)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br></div></div><p>除了默认的二范数外，norm也可以求n范数。方法是指定ord参数。例如：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 一范数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;ord = 1 : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">,</span><span class="token builtin">ord</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 二范数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;ord = 2 : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">,</span><span class="token builtin">ord</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 三范数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;ord = 3 : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">,</span><span class="token builtin">ord</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 四范数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;ord = 4 : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">,</span><span class="token builtin">ord</span><span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 五范数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;ord = 5 : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>origin<span class="token punctuation">,</span><span class="token builtin">ord</span><span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>ord = 1 :  tf.Tensor(4.0, shape=(), dtype=float32)
ord = 2 :  tf.Tensor(2.0, shape=(), dtype=float32)
ord = 3 :  tf.Tensor(1.587401, shape=(), dtype=float32)
ord = 4 :  tf.Tensor(1.4142135, shape=(), dtype=float32)
ord = 5 :  tf.Tensor(1.319508, shape=(), dtype=float32)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="tf-reduce-min-max-mean-sum"><a href="#tf-reduce-min-max-mean-sum" class="header-anchor">#</a> tf.reduce_min / max / mean / sum</h3> <ul><li>tf.reduce_min</li> <li>tf.reduce_max</li> <li>tf.reduce_mean</li> <li>tf.reduce_sum</li></ul> <p>其实就是求最小值最大值平均值。名字里带着reduce表明，这个操作会有一个类似&quot;打平&quot;的过程。例如，当不指定axis参数时，一个[10,4]的tensor会被&quot;打平&quot;成一个[40]的&quot;list&quot;并求最大值、最小值....；再如，带有axis=2参数时，一个[10,4,10]的tensor会被&quot;降维&quot;变成一个元素为[10,4]的tensor的list，大小是10，然后对着十个元素进行最大、最小....运算。</p> <p>在整个tensor上操作：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">,</span><span class="token string">&quot;\nreduce_min = &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_min<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;\nreduce_max = &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;\nreduce_mean = &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  tf.Tensor(
[[-1.4178391e+00  1.0799263e+00  1.8141992e+00 -2.9427743e-01
   3.5776252e-01 -6.9446379e-01 -7.1207196e-01  9.6388352e-01
  -2.1230397e+00  4.8318788e-01]
 [-4.1854006e-01 -2.2664030e-01 -9.8776561e-01  3.3819950e-01
   2.4363371e-02 -3.2178679e+00 -2.8521428e-01 -5.3039378e-01
  -1.0285269e+00 -1.2320877e+00]
 [ 6.0093373e-01  1.3320454e-02  9.5860285e-01  1.4495020e+00
   5.1962131e-01  1.1331964e+00 -1.0149366e+00 -5.1126540e-02
  -5.0443190e-01  3.9746460e-01]
 [-4.1444901e-01 -1.2171540e+00 -8.4814447e-01  1.4405949e+00
   7.2787516e-04  1.2379333e+00  1.0925928e+00 -9.9176753e-01
   3.8999468e-02  1.0164096e+00]], shape=(4, 10), dtype=float32) 
reduce_min =  tf.Tensor(-3.2178679, shape=(), dtype=float32) 
reduce_max =  tf.Tensor(1.8141992, shape=(), dtype=float32) 
reduce_mean =  tf.Tensor(-0.08123293, shape=(), dtype=float32)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>在某个轴上操作：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\nreduce_min on axis 1 = &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_min<span class="token punctuation">(</span>origin<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\nreduce_max on axis 1 = &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>origin<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\nreduce_mean on axis 1 = &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>origin<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  tf.Tensor(
[[-3.1204236   0.67563623 -0.9232384   1.1589053   0.8515049  -0.47955766
  -1.723766    0.12821583 -0.6078169  -0.07115268]
 [-0.03351626  0.5452725   0.4999855  -0.13481826  0.6798329   0.23792107
  -0.6113948   1.3868407   0.24892737 -0.41333905]
 [-0.9676226  -0.3656622  -0.688232    1.721823    0.6695465  -0.44504106
   0.90125936  0.5428907   1.4090685  -0.9626962 ]
 [-0.87203074  0.9285623   0.56897074 -1.4624474   1.8943952  -0.5554827
  -0.8351434  -0.3565093  -1.5708245  -1.1640625 ]], shape=(4, 10), dtype=float32)

reduce_min on axis 1 =  tf.Tensor([-3.1204236 -0.6113948 -0.9676226 -1.5708245], shape=(4,), dtype=float32)

reduce_max on axis 1 =  tf.Tensor([1.1589053 1.3868407 1.721823  1.8943952], shape=(4,), dtype=float32)

reduce_mean on axis 1 =  tf.Tensor([-0.4111693   0.24057117  0.18153341 -0.34245723], shape=(4,), dtype=float32)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h3 id="tf-argmax-argmin"><a href="#tf-argmax-argmin" class="header-anchor">#</a> tf.argmax/argmin</h3> <ul><li>tf.argmax</li> <li>tf.argmin</li></ul> <p>用于求最小值和最大值的位置。当不指定axis参数时，默认再维度0上求每个维度下标下的最大、最小值的位置。</p> <p>argmin</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">)</span>
<span class="token comment"># 维度0下求最大值位置</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;argmax : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  tf.Tensor(
[[ 0.        0.        0.      ]
 [ 0.        0.       54.485176]
 [86.468796 74.000046  0.      ]
 [ 0.       29.033602 69.07481 ]], shape=(4, 3), dtype=float32)
argmax :  tf.Tensor([2 2 3], shape=(3,), dtype=int64)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>argmax</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">)</span>
<span class="token comment"># 维度0下求最大值位置，这里对维度0展开会得到二位的tensor，所以得到的最值得位置也会是二维坐标</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;argmax : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>origin<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  tf.Tensor(
[[[  0.        44.180485]
  [ 60.554047  54.124874]
  [ 11.455048  54.916447]]

 [[  0.        70.35009 ]
  [147.33435  110.680046]
  [  0.        59.37093 ]]

 [[  0.        20.160051]
  [  0.        24.07408 ]
  [  0.         0.      ]]

 [[ 84.53291    0.      ]
  [131.28426  103.82523 ]
  [192.91162   31.05115 ]]], shape=(4, 3, 2), dtype=float32)
argmax :  tf.Tensor(
[[3 1]
 [1 1]
 [3 1]], shape=(3, 2), dtype=int64)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><h3 id="tf-equal"><a href="#tf-equal" class="header-anchor">#</a> tf.equal</h3> <p>用于比较</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;a = &quot;</span><span class="token punctuation">,</span>a<span class="token punctuation">,</span><span class="token string">&quot;, b = &quot;</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span>
result <span class="token operator">=</span> tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Equal : &quot;</span><span class="token punctuation">,</span>result<span class="token punctuation">)</span>
cast_to_int <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>result<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;To int32 : &quot;</span><span class="token punctuation">,</span>cast_to_int<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>a =  tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32) , b =  tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)
Equal :  tf.Tensor([False False False False False], shape=(5,), dtype=bool)
To int32 :  tf.Tensor(0, shape=(), dtype=int32)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>tf.equal在精确度计算过上似乎有点用。例如，当有一个测试数据集，你的模型跑出来的预测值和测试数据的y做一次equal，然后cast成一个数字，根据大小可以判断accuracy。（也就是相同的部分是准确预测的）</p> <h3 id="tf-unique"><a href="#tf-unique" class="header-anchor">#</a> tf.unique</h3> <p>tf.unique能得到一个包含tensor中所有元素的“set”，并且得到另一个idx的tensor用户标注每一个元素在得到的set里的下标。例如：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
result<span class="token punctuation">,</span> idx <span class="token operator">=</span> tf<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>origin<span class="token punctuation">)</span> 
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">,</span><span class="token string">&quot;\nunique : &quot;</span><span class="token punctuation">,</span>result<span class="token punctuation">,</span><span class="token string">&quot;, \nidx : &quot;</span><span class="token punctuation">,</span>idx<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  tf.Tensor([4 2 2 4 3], shape=(5,), dtype=int32) 
unique :  tf.Tensor([4 2 3], shape=(3,), dtype=int32) , 
idx :  tf.Tensor([0 1 1 0 2], shape=(5,), dtype=int32)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>回忆一下tf2基本操作中的gather，我们可以通过得到的结果的得到的idx将它复原</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>origin <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
result<span class="token punctuation">,</span> idx <span class="token operator">=</span> tf<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>origin<span class="token punctuation">)</span> 
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;origin = &quot;</span><span class="token punctuation">,</span>origin<span class="token punctuation">,</span><span class="token string">&quot;\nunique : &quot;</span><span class="token punctuation">,</span>result<span class="token punctuation">,</span><span class="token string">&quot;, \nidx : &quot;</span><span class="token punctuation">,</span>idx<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;using tf.gather : &quot;</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>result<span class="token punctuation">,</span>idx<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>输出：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>origin =  tf.Tensor([4 2 2 4 3], shape=(5,), dtype=int32) 
unique :  tf.Tensor([4 2 3], shape=(3,), dtype=int32) , 
idx :  tf.Tensor([0 1 1 0 2], shape=(5,), dtype=int32)
using tf.gather :  tf.Tensor([4 2 2 4 3], shape=(5,), dtype=int32)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新时间:</span> <span class="time">5/5/2021, 8:29:12 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/ch-1/[1]operation-on-tensors-1.html" class="prev">
        Tensor的基本操作：索引、切片和广播
      </a></span> <span class="next"><a href="/ch-1/[3]operator-for-tensors.html">
        张量的基本数学运算
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.a1fbffca.js" defer></script><script src="/assets/js/2.8096074b.js" defer></script><script src="/assets/js/40.716fd348.js" defer></script>
  </body>
</html>
