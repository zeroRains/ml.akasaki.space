(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{382:function(t,s,a){t.exports=a.p+"assets/img/image-20210413100216656.2b41ec7a.png"},520:function(t,s,a){"use strict";a.r(s);var n=a(46),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"眼熟的代码块"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#眼熟的代码块"}},[t._v("#")]),t._v(" 眼熟的代码块")]),t._v(" "),n("p",[t._v("这些代码块经常被使用。建议熟悉它们，并经常看看它们。")]),t._v(" "),n("h2",{attrs:{id:"_1-数据集相关"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-数据集相关"}},[t._v("#")]),t._v(" 1.数据集相关")]),t._v(" "),n("h3",{attrs:{id:"_1-1-使用tensorflow自带的工具加载常见数据集"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-使用tensorflow自带的工具加载常见数据集"}},[t._v("#")]),t._v(" 1.1 使用tensorflow自带的工具加载常见数据集")]),t._v(" "),n("p",[t._v("tensorflow包含了"),n("a",{attrs:{href:"https://en.wikipedia.org/wiki/MNIST_database",target:"_blank",rel:"noopener noreferrer"}},[t._v("mnist"),n("OutboundLink")],1),t._v("、fashion-mnist、cifar-10、cifar-100以及boston_housing等数据集的下载、读取功能。读取这些数据，你需要import相关包：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datasets\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[n("code",[t._v("tensorflow.keras.dataset")]),t._v("包含的数据集读取方法返回训练集和测试集。")]),t._v(" "),n("h4",{attrs:{id:"_1-1-1-载入数据集中的数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-1-载入数据集中的数据"}},[t._v("#")]),t._v(" 1.1.1 载入数据集中的数据")]),t._v(" "),n("p",[t._v("例子：载入mnist手写识别数据集中的数据：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" testing_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datasets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mnist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("例子：载入fashion-mnist服装数据集中的数据：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" testing_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datasets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fashion_mnist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("你应该大致掌握了相应方法，它有一个通用的写法：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" testing_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datasets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("数据集名称"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("这时你会得到四个数据部分，也就是训练集的图像"),n("code",[t._v("training_x")]),t._v("、训练图像对应的标签"),n("code",[t._v("training_y")]),t._v("、测试集的图像"),n("code",[t._v("testing_x")]),t._v("以及测试集的图像对应的标签"),n("code",[t._v("testing_y")]),t._v("。")]),t._v(" "),n("p",[t._v("此时你可以显示和检查一部分图片。详见本页的"),n("strong",[t._v("1.2 查看部分数据集中图像")]),t._v("中相关内容。")]),t._v(" "),n("h4",{attrs:{id:"_1-1-2-构建数据集"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-2-构建数据集"}},[t._v("#")]),t._v(" 1.1.2 构建数据集")]),t._v(" "),n("p",[t._v("此时应该让这些数据成为两个小数据集，第一个是训练数据集，第二个是测试数据集。你可以使用"),n("code",[t._v("tensorflow.data.Dataset.from_tensor_slices()")]),t._v("方法完成这个过程：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("training_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntesting_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" testing_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("p",[t._v("当然，你也可以不这样做。具体取决于你希望怎么迭代你的数据集。上述方法也不仅限于从tensorflow工具包里导入的数据集，在本地的数据集也可以被这样构建为运行时数据集。")]),t._v(" "),n("h4",{attrs:{id:"_1-1-3-标准化和前处理"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-3-标准化和前处理"}},[t._v("#")]),t._v(" 1.1.3 标准化和前处理")]),t._v(" "),n("p",[t._v("如果你不知道什么是标准化，请参考"),n("RouterLink",{attrs:{to:"/appendix/similar-vocabularies.html"}},[t._v("附录-常见名词")]),t._v("中有关标准化、去量纲的词条。``")],1),t._v(" "),n("p",[t._v("在训练图像数据时，特征图一般是float32的，并且要标准化。而对应的标签一般是整数（索引）。所以，我们一般对x和y做以下前处理：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("training_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("astype"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'float32'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntesting_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("astype"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'float32'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("h4",{attrs:{id:"_1-1-4-指定batch大小以及将数据集打乱"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-4-指定batch大小以及将数据集打乱"}},[t._v("#")]),t._v(" 1.1.4 指定batch大小以及将数据集打乱")]),t._v(" "),n("p",[t._v("在你经常看到各种SGD（参阅"),n("RouterLink",{attrs:{to:"/appendix/similar-vocabularies.html"}},[t._v("附录-常见名词")]),t._v("中关于随机梯度下降的词条）方法中，需要批量取用数据集，也就是我们经常指定的batch。tensorflow也提供了指定"),n("code",[t._v("Dataset")]),t._v("对象batch size的方法：")],1),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("training_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" training_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("128")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("在这之后，往往我们将数据集打乱：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("training_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" training_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shuffle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("testing_x和testing_y是否有必要打乱请自行根据需求决定。")]),t._v(" "),n("h4",{attrs:{id:"_1-1-5-总结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-5-总结"}},[t._v("#")]),t._v(" 1.1.5 总结")]),t._v(" "),n("p",[t._v("把上面的整个过程写在一起，就是：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tensorflow "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tf\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datasets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" initializers\n\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" testing_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datasets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fashion_mnist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntraining_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("astype"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'float32'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntesting_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("astype"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'float32'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbatch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("128")]),t._v("\n\ntraining_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntraining_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" training_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntesting_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testing_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" testing_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntesting_dataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" testing_dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br")])]),n("p",[t._v("于是你的到了一份可以直接投入训练和测试的数据集。")]),t._v(" "),n("h3",{attrs:{id:"_1-2-查看部分数据集中图像"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-查看部分数据集中图像"}},[t._v("#")]),t._v(" 1.2 查看部分数据集中图像")]),t._v(" "),n("p",[t._v("当你导入了一些图片作为数据集时，可以显示一部分图片，检查导入的是否正确。这不是必要的，但是很好玩。我们定义一个这样的函数方便经常使用：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" math\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("check_image_in_dataset_via_plot")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" how_many"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("36")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gray_scale"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    plt_width "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ceil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("how_many "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("figsize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("plt_width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" plt_width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("round")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("how_many"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("plt_width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" plt_width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xticks"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yticks"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("grid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" gray_scale"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("imshow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("imshow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cmap"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("binary"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# marking index under the picture")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# plt.xlabel(class_names[labels[i][0]])")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br")])]),n("p",[t._v("其中"),n("code",[t._v("dataset")]),t._v("是一个list，其中包含若干图片。"),n("code",[t._v("how_many")]),t._v("决定你要显示几张图片，"),n("code",[t._v("gray_scale")]),t._v("决定是否显示为灰度图（可以指定灰度是因为有的数据集确实是灰度图，比如"),n("code",[t._v("fashion-mnist")]),t._v("）。")]),t._v(" "),n("p",[t._v("举个使用的例子，我们导入了一份"),n("code",[t._v("fashion-mnist")]),t._v("数据集中的图片，显示其中的36灰度图：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("check_image_in_dataset_via_plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("imsges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" how_many"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("36")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gray_scale"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("其中images是图像的list。你会看到这样的显示：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(382),alt:"image-20210413100216656"}})]),t._v(" "),n("h2",{attrs:{id:"_2-计算机视觉相关"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-计算机视觉相关"}},[t._v("#")]),t._v(" 2.计算机视觉相关")])])}),[],!1,null,null,null);s.default=e.exports}}]);