(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{398:function(t,s,a){t.exports=a.p+"assets/img/3.2_output1.5727781b.png"},536:function(t,s,a){"use strict";a.r(s);var n=a(46),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"线性回归代码实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#线性回归代码实现"}},[t._v("#")]),t._v(" 线性回归代码实现")]),t._v(" "),n("p",[t._v("在了解了线性回归的背景知识之后，现在我们可以动手实现它了。尽管强大的深度学习框架可以减少大量重复性工作，但若过于依赖它提供的便利，会导致我们很难深入理解深度学习是如何工作的。因此，本节将介绍如何只利用"),n("code",[t._v("Tensor")]),t._v("和"),n("code",[t._v("GradientTape")]),t._v("来实现一个线性回归的训练。")]),t._v(" "),n("p",[t._v("首先，导入本节中实验所需的包或模块，其中的matplotlib包可用于作图，且设置成嵌入显示。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("matplotlib inline\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tensorflow "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tf\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__version__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" matplotlib "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" random\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br")])]),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("    2.0.0\n")])])]),n("h2",{attrs:{id:"手动实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#手动实现"}},[t._v("#")]),t._v(" 手动实现")]),t._v(" "),n("h3",{attrs:{id:"生成数据集"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#生成数据集"}},[t._v("#")]),t._v(" 生成数据集")]),t._v(" "),n("p",[t._v("我们构造一个简单的人工训练数据集，它可以使我们能够直观比较学到的参数和真实的模型参数的区别。设训练数据集样本数为1000，输入个数（特征数）为2。给定随机生成的批量样本特征 "),n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[n("semantics",[n("mrow",[n("mi",{attrs:{mathvariant:"bold-italic"}},[t._v("X")]),n("mo",[t._v("∈")]),n("msup",[n("mi",{attrs:{mathvariant:"double-struck"}},[t._v("R")]),n("mrow",[n("mn",[t._v("1000")]),n("mo",[t._v("×")]),n("mn",[t._v("2")])],1)],1)],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\boldsymbol{X} \\in \\mathbb{R}^{1000 \\times 2}")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.72521em","vertical-align":"-0.0391em"}}),n("span",{staticClass:"mord"},[n("span",{staticClass:"mord"},[n("span",{staticClass:"mord boldsymbol",staticStyle:{"margin-right":"0.07778em"}},[t._v("X")])])]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),n("span",{staticClass:"mrel"},[t._v("∈")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.8141079999999999em","vertical-align":"0em"}}),n("span",{staticClass:"mord"},[n("span",{staticClass:"mord mathbb"},[t._v("R")]),n("span",{staticClass:"msupsub"},[n("span",{staticClass:"vlist-t"},[n("span",{staticClass:"vlist-r"},[n("span",{staticClass:"vlist",staticStyle:{height:"0.8141079999999999em"}},[n("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[n("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),n("span",{staticClass:"sizing reset-size6 size3 mtight"},[n("span",{staticClass:"mord mtight"},[n("span",{staticClass:"mord mtight"},[t._v("1000")]),n("span",{staticClass:"mbin mtight"},[t._v("×")]),n("span",{staticClass:"mord mtight"},[t._v("2")])])])])])])])])])])])]),t._v("，我们使用线性回归模型真实权重 "),n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[n("semantics",[n("mrow",[n("mi",{attrs:{mathvariant:"bold-italic"}},[t._v("w")]),n("mo",[t._v("=")]),n("mo",{attrs:{stretchy:"false"}},[t._v("[")]),n("mn",[t._v("2")]),n("mo",{attrs:{separator:"true"}},[t._v(",")]),n("mo",[t._v("−")]),n("mn",[t._v("3.4")]),n("msup",[n("mo",{attrs:{stretchy:"false"}},[t._v("]")]),n("mi",{attrs:{mathvariant:"normal"}},[t._v("⊤")])],1)],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\boldsymbol{w} = [2, -3.4]^\\top")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.44444em","vertical-align":"0em"}}),n("span",{staticClass:"mord"},[n("span",{staticClass:"mord"},[n("span",{staticClass:"mord boldsymbol",staticStyle:{"margin-right":"0.02778em"}},[t._v("w")])])]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),n("span",{staticClass:"mrel"},[t._v("=")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"1.099108em","vertical-align":"-0.25em"}}),n("span",{staticClass:"mopen"},[t._v("[")]),n("span",{staticClass:"mord"},[t._v("2")]),n("span",{staticClass:"mpunct"},[t._v(",")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.16666666666666666em"}}),n("span",{staticClass:"mord"},[t._v("−")]),n("span",{staticClass:"mord"},[t._v("3.4")]),n("span",{staticClass:"mclose"},[n("span",{staticClass:"mclose"},[t._v("]")]),n("span",{staticClass:"msupsub"},[n("span",{staticClass:"vlist-t"},[n("span",{staticClass:"vlist-r"},[n("span",{staticClass:"vlist",staticStyle:{height:"0.849108em"}},[n("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[n("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),n("span",{staticClass:"sizing reset-size6 size3 mtight"},[n("span",{staticClass:"mord mtight"},[t._v("⊤")])])])])])])])])])])]),t._v(" 和偏差 "),n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[n("semantics",[n("mrow",[n("mi",[t._v("b")]),n("mo",[t._v("=")]),n("mn",[t._v("4.2")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("b = 4.2")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.69444em","vertical-align":"0em"}}),n("span",{staticClass:"mord mathnormal"},[t._v("b")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),n("span",{staticClass:"mrel"},[t._v("=")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.64444em","vertical-align":"0em"}}),n("span",{staticClass:"mord"},[t._v("4.2")])])])]),t._v("，以及一个随机噪声项 "),n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[n("semantics",[n("mrow",[n("mi",[t._v("ϵ")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\epsilon")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),n("span",{staticClass:"mord mathnormal"},[t._v("ϵ")])])])]),t._v(" 来生成标签")]),t._v(" "),n("p",{staticClass:"katex-block"},[n("span",{staticClass:"katex-display"},[n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"}},[n("semantics",[n("mrow",[n("mi",{attrs:{mathvariant:"bold-italic"}},[t._v("y")]),n("mo",[t._v("=")]),n("mi",{attrs:{mathvariant:"bold-italic"}},[t._v("X")]),n("mi",{attrs:{mathvariant:"bold-italic"}},[t._v("w")]),n("mo",[t._v("+")]),n("mi",[t._v("b")]),n("mo",[t._v("+")]),n("mi",[t._v("ϵ")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\boldsymbol{y} = \\boldsymbol{X}\\boldsymbol{w} + b + \\epsilon\n")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.63888em","vertical-align":"-0.19444em"}}),n("span",{staticClass:"mord"},[n("span",{staticClass:"mord"},[n("span",{staticClass:"mord boldsymbol",staticStyle:{"margin-right":"0.03704em"}},[t._v("y")])])]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),n("span",{staticClass:"mrel"},[t._v("=")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.76944em","vertical-align":"-0.08333em"}}),n("span",{staticClass:"mord"},[n("span",{staticClass:"mord"},[n("span",{staticClass:"mord boldsymbol",staticStyle:{"margin-right":"0.07778em"}},[t._v("X")])])]),n("span",{staticClass:"mord"},[n("span",{staticClass:"mord"},[n("span",{staticClass:"mord boldsymbol",staticStyle:{"margin-right":"0.02778em"}},[t._v("w")])])]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),n("span",{staticClass:"mbin"},[t._v("+")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}})]),n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.77777em","vertical-align":"-0.08333em"}}),n("span",{staticClass:"mord mathnormal"},[t._v("b")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),n("span",{staticClass:"mbin"},[t._v("+")]),n("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}})]),n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),n("span",{staticClass:"mord mathnormal"},[t._v("ϵ")])])])])])]),t._v(" "),n("p",[t._v("其中噪声项 "),n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[n("semantics",[n("mrow",[n("mi",[t._v("ϵ")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\epsilon")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"base"},[n("span",{staticClass:"strut",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),n("span",{staticClass:"mord mathnormal"},[t._v("ϵ")])])])]),t._v(" 服从均值为0、标准差为0.01的正态分布。噪声代表了数据集中无意义的干扰。下面，让我们生成数据集。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("num_inputs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\nnum_examples "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),t._v("\ntrue_w "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ntrue_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4.2")]),t._v("\nfeatures "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("stddev "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" true_b\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("stddev"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br")])]),n("p",[t._v("注意，"),n("code",[t._v("features")]),t._v("的每一行是一个长度为2的向量，而"),n("code",[t._v("labels")]),t._v("的每一行是一个长度为1的向量（标量）。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("输出：")]),t._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("(<tf.Tensor: id=31, shape=(2,), dtype=float32, numpy=array([0.24220389, 0.41220406], dtype=float32)>,\n <tf.Tensor: id=35, shape=(), dtype=float32, numpy=3.3064191>)\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("p",[t._v("通过生成第二个特征"),n("code",[t._v("features[:, 1]")]),t._v("和标签 "),n("code",[t._v("labels")]),t._v(" 的散点图，可以更直观地观察两者间的线性关系。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("set_figsize")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("figsize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'figure.figsize'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" figsize\n\nset_figsize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br")])]),n("p",[n("img",{attrs:{src:a(398),alt:"img"}})]),t._v(" "),n("h3",{attrs:{id:"读取数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#读取数据"}},[t._v("#")]),t._v(" 读取数据")]),t._v(" "),n("p",[t._v("在训练模型的时候，我们需要遍历数据集并不断读取小批量数据样本。这里我们定义一个函数：它每次返回"),n("code",[t._v("batch_size")]),t._v("（批量大小）个随机样本的特征和标签。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("data_iter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    num_examples "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    indices "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shuffle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("indices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        j "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" indices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("min")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gather"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indices"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gather"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indices"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br")])]),n("p",[t._v("让我们读取第一个小批量数据样本并打印。每个批量的特征形状为(10, 2)，分别对应批量大小和输入个数；标签形状为批量大小。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("batch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" data_iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br")])]),n("p",[t._v("输出：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("tf.Tensor(\n[[ 0.04718596 -1.5959413 ]\n [ 0.3889716  -1.5288432 ]\n [-1.8489572   1.66422   ]\n [-1.3978077  -0.85818154]\n [-0.36940867 -0.619267  ]\n [-0.15660426  1.1231796 ]\n [ 0.89411694  1.5499148 ]\n [ 1.9971682  -0.56981105]\n [-2.1852891   0.18805206]\n [ 1.3222371  -1.0301086 ]], shape=(10, 2), dtype=float32) tf.Tensor(\n[ 9.738684   10.164594   -5.15065     4.3305573   5.568048    0.06494669\n  0.7251317  10.128626   -0.8036391  10.343082  ], shape=(10,), dtype=float32)\n")])])]),n("h3",{attrs:{id:"初始化模型参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#初始化模型参数"}},[t._v("#")]),t._v(" 初始化模型参数")]),t._v(" "),n("p",[t._v("我们将权重初始化成均值为0、标准差为0.01的正态随机数，偏差则初始化成0。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("w "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stddev"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nb "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("h3",{attrs:{id:"定义模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#定义模型"}},[t._v("#")]),t._v(" 定义模型")]),t._v(" "),n("p",[t._v("下面是线性回归的矢量计算表达式的实现。我们使用"),n("code",[t._v("matmul")]),t._v("函数做矩阵乘法。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("linreg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("h3",{attrs:{id:"定义损失函数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#定义损失函数"}},[t._v("#")]),t._v(" 定义损失函数")]),t._v(" "),n("p",[t._v("我们使用上一节描述的平方损失来定义线性回归的损失函数。在实现中，我们需要把真实值"),n("code",[t._v("y")]),t._v("变形成预测值"),n("code",[t._v("y_hat")]),t._v("的形状。以下函数返回的结果也将和"),n("code",[t._v("y_hat")]),t._v("的形状相同。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("squared_loss")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_hat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_hat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_hat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("h3",{attrs:{id:"定义优化算法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#定义优化算法"}},[t._v("#")]),t._v(" 定义优化算法")]),t._v(" "),n("p",[t._v("以下的"),n("code",[t._v("sgd")]),t._v("函数实现了上一节中介绍的小批量随机梯度下降算法。它通过不断迭代模型参数来优化损失函数。这里自动求梯度模块计算得来的梯度是一个批量样本的梯度和。我们将它除以批量大小来得到平均值。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sgd")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" grads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Mini-batch stochastic gradient descent."""')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" param "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        param"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("assign_sub"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" grads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br")])]),n("h3",{attrs:{id:"训练模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#训练模型"}},[t._v("#")]),t._v(" 训练模型")]),t._v(" "),n("p",[t._v("在训练中，我们将多次迭代模型参数。在每次迭代中，我们根据当前读取的小批量数据样本（特征"),n("code",[t._v("X")]),t._v("和标签"),n("code",[t._v("y")]),t._v("），通过调用反向函数"),n("code",[t._v("t.gradients")]),t._v("计算小批量随机梯度，并调用优化算法"),n("code",[t._v("sgd")]),t._v("迭代模型参数。由于我们之前设批量大小"),n("code",[t._v("batch_size")]),t._v("为10，每个小批量的损失"),n("code",[t._v("l")]),t._v("的形状为(10, 1)。回忆一下自动求梯度一节。由于变量"),n("code",[t._v("l")]),t._v("并不是一个标量，所以我们可以调用"),n("code",[t._v("reduce_sum()")]),t._v("将其求和得到一个标量，再运行"),n("code",[t._v("t.gradients")]),t._v("得到该变量有关模型参数的梯度。注意在每次更新完参数后不要忘了将参数的梯度清零。")]),t._v(" "),n("p",[t._v("在一个迭代周期（epoch）中，我们将完整遍历一遍"),n("code",[t._v("data_iter")]),t._v("函数，并对训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。这里的迭代周期个数"),n("code",[t._v("num_epochs")]),t._v("和学习率"),n("code",[t._v("lr")]),t._v("都是超参数，分别设3和0.03。在实践中，大多超参数都需要通过反复试错来不断调节。虽然迭代周期数设得越大模型可能越有效，但是训练时间可能过长。而有关学习率对模型的影响，我们会在后面“优化算法”一章中详细介绍。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("lr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.03")]),t._v("\nnum_epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" linreg\nloss "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" squared_loss\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" epoch "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_epochs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" data_iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientTape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("watch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            l "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_sum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        grads "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gradient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        sgd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" grads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    train_l "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch %d, loss %f'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])]),n("p",[t._v("输出：")]),t._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v(" epoch 1, loss 0.028907 epoch 2, loss 0.000101 epoch 3, loss 0.000049\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("训练完成后，我们可以比较学到的参数和用来生成训练集的真实参数。它们应该很接近。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("true_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("p",[t._v("输出：")]),t._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("([2, -3.4], <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy= array([[ 1.9994558], [-3.3993363]], dtype=float32)>) (4.2, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([4.199041], dtype=float32)>)\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("h2",{attrs:{id:"使用框架实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用框架实现"}},[t._v("#")]),t._v(" 使用框架实现")]),t._v(" "),n("p",[t._v("随着深度学习框架的发展，开发深度学习应用变得越来越便利。实践中，我们通常可以用比上一节更简洁的代码来实现同样的模型。在本节中，我们将介绍如何使用tensorflow2.0推荐的keras接口更方便地实现线性回归的训练。")]),t._v(" "),n("h3",{attrs:{id:"生成数据集-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#生成数据集-2"}},[t._v("#")]),t._v(" 生成数据集")]),t._v(" "),n("p",[t._v("我们生成与上一节中相同的数据集。其中"),n("code",[t._v("features")]),t._v("是训练数据特征，"),n("code",[t._v("labels")]),t._v("是标签。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tensorflow "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tf\n\nnum_inputs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\nnum_examples "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),t._v("\ntrue_w "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ntrue_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4.2")]),t._v("\nfeatures "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stddev"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" true_b\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stddev"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br")])]),n("h3",{attrs:{id:"读取数据-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#读取数据-2"}},[t._v("#")]),t._v(" 读取数据")]),t._v(" "),n("p",[t._v("虽然tensorflow2.0对于线性回归可以直接拟合，不用再划分数据集，但我们仍学习一下读取数据的方法")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" data "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tfdata\n\nbatch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将训练数据的特征和标签组合")]),t._v("\ndataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tfdata"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 随机读取小批量")]),t._v("\ndataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shuffle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buffer_size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \ndataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndata_iter "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("iter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br")])]),n("p",[n("code",[t._v("shuffle")]),t._v(" 的 "),n("code",[t._v("buffer_size")]),t._v(" 参数应大于等于样本数，"),n("code",[t._v("batch")]),t._v(" 可以指定 "),n("code",[t._v("batch_size")]),t._v(" 的分割大小。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" data_iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br")])]),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("tf.Tensor(\n[[ 1.2856768   1.3815335 ]\n [ 1.1151928  -1.3777982 ]\n [ 0.6097271   1.3478378 ]\n [ 2.1615875   1.52963   ]\n [-1.3143488  -0.79531455]\n [-2.495006    0.3701927 ]\n [-0.07739297 -0.8636043 ]\n [-0.18479416 -1.5275241 ]\n [-0.3426277  -0.01935842]\n [ 0.25231913  1.4940815 ]], shape=(10, 2), dtype=float32) tf.Tensor(\n[ 2.0673854  11.10116     0.8320709   3.3300133   4.272185   -2.062947\n  6.981174    9.027803    3.5848885  -0.39152586], shape=(10,),     dtype=float32)\n")])])]),n("p",[t._v("使用"),n("code",[t._v("iter(dataset)")]),t._v("的方式，只能遍历数据集一次，是一种比较 tricky 的写法，为了复刻原书表达才这样写。这里也给出一种在"),n("a",{attrs:{href:"https://www.tensorflow.org/guide/eager?hl=zh_cn#computing_gradients",target:"_blank",rel:"noopener noreferrer"}},[t._v("官方文档"),n("OutboundLink")],1),t._v("中推荐的写法：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br")])]),n("h3",{attrs:{id:"定义模型和初始化参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#定义模型和初始化参数"}},[t._v("#")]),t._v(" 定义模型和初始化参数")]),t._v(" "),n("p",[n("code",[t._v("Tensorflow 2.0")]),t._v("推荐使用"),n("code",[t._v("Keras")]),t._v("定义网络，故使用"),n("code",[t._v("Keras")]),t._v("定义网络。我们先定义一个模型变量"),n("code",[t._v("model")]),t._v("，它是一个"),n("code",[t._v("Sequential")]),t._v("实例。在"),n("code",[t._v("Keras")]),t._v("中，"),n("code",[t._v("Sequential")]),t._v("实例可以看作是一个串联各个层的容器。在构造模型时，我们在该容器中依次添加层。当给定输入数据时，容器中的每一层将依次推断下一层的输入尺寸。重要的一点是，在"),n("code",[t._v("Keras")]),t._v("中我们无须指定每一层输入的形状。线性回归，输入层与输出层等效为一层全连接层"),n("code",[t._v("keras.layers.Dense()")]),t._v("。")]),t._v(" "),n("p",[n("code",[t._v("Keras")]),t._v(" 中初始化参数由 "),n("code",[t._v("kernel_initializer")]),t._v(" 和 "),n("code",[t._v("bias_initializer")]),t._v(" 选项分别设置权重和偏置的初始化方式。我们从 "),n("code",[t._v("tensorflow")]),t._v(" 导入 "),n("code",[t._v("initializers")]),t._v(" 模块，指定权重参数每个元素将在初始化时随机采样于均值为0、标准差为0.01的正态分布。偏差参数默认会初始化为零。"),n("code",[t._v("RandomNormal(stddev=0.01)")]),t._v("指定权重参数每个元素将在初始化时随机采样于均值为0、标准差为0.01的正态分布。偏差参数默认会初始化为零。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" keras\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" layers\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" initializers "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" init\nmodel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kernel_initializer"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RandomNormal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("stddev"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br")])]),n("h3",{attrs:{id:"定义损失函数-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#定义损失函数-2"}},[t._v("#")]),t._v(" 定义损失函数")]),t._v(" "),n("p",[n("code",[t._v("Tensoflow")]),t._v("在"),n("code",[t._v("losses")]),t._v("模块中提供了各种损失函数和自定义损失函数的基类，并直接使用它的均方误差损失作为模型的损失函数。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" losses\nloss "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" losses"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MeanSquaredError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("h3",{attrs:{id:"定义优化算法-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#定义优化算法-2"}},[t._v("#")]),t._v(" 定义优化算法")]),t._v(" "),n("p",[t._v("同样，我们也无须自己实现小批量随机梯度下降算法。"),n("code",[t._v("tensorflow.keras.optimizers")]),t._v(" 模块提供了很多常用的优化算法比如SGD、Adam和RMSProp等。下面我们创建一个用于优化model 所有参数的优化器实例，并指定学习率为0.03的小批量随机梯度下降（SGD）为优化算法。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tensorflow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" optimizers\ntrainer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" optimizers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.03")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("h3",{attrs:{id:"训练模型-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#训练模型-2"}},[t._v("#")]),t._v(" 训练模型")]),t._v(" "),n("p",[t._v("在使用"),n("code",[t._v("Tensorflow")]),t._v("训练模型时，我们通过调用"),n("code",[t._v("tensorflow.GradientTape")]),t._v("记录动态图梯度，执行"),n("code",[t._v("tape.gradient")]),t._v("获得动态图中各变量梯度。通过 "),n("code",[t._v("model.trainable_variables")]),t._v(" 找到需要更新的变量，并用 "),n("code",[t._v("trainer.apply_gradients")]),t._v(" 更新权重，完成一步训练。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("num_epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" epoch "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientTape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            l "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        grads "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gradient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("trainable_variables"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        trainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply_gradients"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("zip")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("grads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("trainable_variables"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    l "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch %d, loss: %f'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br")])]),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("epoch 1, loss: 0.519287\nepoch 2, loss: 0.008997\nepoch 3, loss: 0.000261\n")])])]),n("p",[t._v("下面我们分别比较学到的模型参数和真实的模型参数。我们可以通过model的"),n("code",[t._v("get_weights()")]),t._v("来获得其权重（"),n("code",[t._v("weight")]),t._v("）和偏差（"),n("code",[t._v("bias")]),t._v("）。学到的参数和真实的参数很接近。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_weights"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("([2, -3.4], array([[ 1.9930198],\n    [-3.3977082]], dtype=float32))\n")])])]),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("true_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_weights"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("(4.2, array([4.1895046], dtype=float32))\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);