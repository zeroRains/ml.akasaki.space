(window.webpackJsonp=window.webpackJsonp||[]).push([[54],{563:function(e,t,o){"use strict";o.r(t);var a=o(46),n=Object(a.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h1",{attrs:{id:"deeplab-semantic-image-segmentation-with-deep-convolutional-nets-atrous-convolution-and-fully-connected-crfs"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#deeplab-semantic-image-segmentation-with-deep-convolutional-nets-atrous-convolution-and-fully-connected-crfs"}},[e._v("#")]),e._v(" DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs")]),e._v(" "),o("h3",{attrs:{id:"这篇笔记的写作者是visualdust。"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#这篇笔记的写作者是visualdust。"}},[e._v("#")]),e._v(" 这篇笔记的写作者是"),o("a",{attrs:{href:"https://github.com/visualDust",target:"_blank",rel:"noopener noreferrer"}},[e._v("VisualDust"),o("OutboundLink")],1),e._v("。")]),e._v(" "),o("blockquote",[o("p",[e._v("In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed \"DeepLab\" system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7% mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.")])]),e._v(" "),o("p",[e._v("咳咳，还没有开始写")])])}),[],!1,null,null,null);t.default=n.exports}}]);